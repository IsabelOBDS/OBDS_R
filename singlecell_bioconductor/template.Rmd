---
title: "Template code for single-cell analysis using Bioconductor"
author: "Kevin Rue-Albrecht"
date: "05/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
# library(   )
```

# Exercise

## Import scRNA-seq data and create a SingleCellExperiment object

- Import the filtered matrix into R; use `DropletUtils`.

**Note:** use the `samples=` argument of the `DropletUtils::read10xCounts()` function to give a memorable name to each sample.
  Check the difference without using the `samples` argument.

```{r}
library(DropletUtils)
sce <- read10xCounts(samples = "/project/obds/shared/resources/4_r_single_cell/singlecell_bioconductor/filtered_feature_bc_matrix/", sample.names = "pbm5c")

sce2 <- DropletUtils::read10xCounts(
  samples = c("pbm5c" = "/project/obds/shared/resources/4_r_single_cell/singlecell_bioconductor/filtered_feature_bc_matrix/")
)
```

- Print the object.
  What can you tell about its contents?
  
```{r}
sce
sce2
rowData(sce2)
colData(sce2)
```

> Answer:
>
  
- What can you tell from the object metadata?

**Note:** slots of `SummarizedExperiment` objects are typically accessed using functions of the same name, e.g. `metadata()`.

```{r}
metadata(sce)
metadata(sce2) #going to use this version as it correctly lables the samples with pmb5c

```

> Answer:
>

# Exercise

## Quality control

- Compute and visualise quality control metrics (library size, genes detected, mitochondrial fraction); use `scuttle` and/or `scater`.

  + Identify mitochondrial genes and pass those to the `subsets` argument of the `scuttle::addPerCellQC()` function.

  + What is the return value?
    Where are the quality metrics stored?
    What is the difference with `scuttle::perCellQCMetrics()`?

```{r}
is.mito <- grep(rowData(sce2)$Symbol, pattern = "^MT-", value = FALSE) 
#if you do not include value = TRUE,it will give you the index value for where the MT genes are . if TRUE it will give you the gene names. the indexes are needed for scuttle function below (addPerrCellQC)
```

```{r}
library(scuttle)
sce <- scuttle::addPerCellQC(sce2, subset = list(MT = is.mito)  )
#name of the list 'MT' is important to be able to distinguish things later

rowData(sce)
colData(sce)

```

> Answer:
>

- Visualise library size, genes detected and mitochondrial fraction as three violin plots; use `ggplot2`.

```{r}
library("tidyverse")
plot1 <- colData(sce) %>%
    as_tibble() %>% 
    ggplot() +
    geom_violin(aes(x = Sample, y = sum)) +
    labs(x = "Total UMI", y = "Value")
plot2 <- colData(sce) %>%
    as_tibble() %>% 
    ggplot() +
    geom_violin(aes(x = Sample, y = detected   )) +
    labs(x = "Genes detected", y = "Value")
plot3 <- colData(sce) %>%
    as_tibble() %>% 
    ggplot() +
    geom_violin(aes(x = Sample, y = subsets_MT_percent   )) +
    labs(x = "Percentage mitochondrial", y = "Value")
cowplot::plot_grid(plot1, plot2, plot3, nrow = 1)
```

- Filter cells, keeping those with more than 4,500 UMI, less than 15% mitochondrial UMI, and more than 1,500 genes detected. 

```{r}

sce <- sce[, sce$sum > 4500 & sce$subsets_MT_percent < 15 & sce$detected > 1500]
sce
```

- Similarly, use `scuttle::perFeatureQCMetrics()` or `scuttle::addPerFeatureQC()` to compute per-feature quality metrics, and visualise those metrics.

```{r}
sce <- scuttle::addPerFeatureQC(sce)
sce
```

```{r}
## ggplot2
#rows have information 

rowData(sce)
 plot5 <- rowData(sce) %>% 
  as_tibble() %>% 
  ggplot() +
  geom_point(aes(x = detected, y = mean))

```

# Exercise step 3. Normalisation

- Convert the counts into normalized expression values to eliminate cell-specific biases (e.g., in capture efficiency); use `scuttle` and/or `scran`.
  Display the names of the assays available after that step.

**Note:** use `scuttle::logNormCounts()` to compute log-normalised counts.
  What is the return value?
  Where can you find the normalised counts?

```{r}
library(scuttle)
sce <- scuttle::logNormCounts(sce)
assayNames(sce)
assay(sce, "logcounts")
```

> Answer:
> 

- Plot the variance against the mean of each gene.

**Note:** how can you tell whether the normalisation was effective?
  Compare with https://osca.bioconductor.org/feature-selection.html#quantifying-per-gene-variation

```{r}
library(DelayedMatrixStats)
#
x <- DelayedArray(assay(sce, "counts"))
plot_data <- tibble(
    mean = DelayedMatrixStats::rowMeans2(x),
    variance = DelayedMatrixStats::rowVars(x)
)
plot_counts <- ggplot(plot_data, aes(x = mean, y = variance)   ) +
    geom_point()
#
x <- DelayedArray(assay(sce, "logcounts"))
plot_data <- tibble(
    mean = DelayedMatrixStats::rowMeans2(x),
    variance = DelayedMatrixStats::rowVars(x)
)
plot_logcounts <- ggplot(plot_data, aes(x = mean, y = variance)   ) +
    geom_point()
cowplot::plot_grid(plot_counts, plot_logcounts, nrow = 1)
#variance is more stable in the log transformed data
```

> Answer:
> 

- When would you rather use `scuttle::computePooledFactors` instead?

> Answer:
> 
> 

# Exercise

## Feature selection

Select features for downstream analyses, e.g. highly variable genes; use `scran`.

- Use `scran::modelGeneVar()` to model the variance of the log-expression profiles for each gene.
  What is the output?

```{r}
library(scran)
dec <- scran::modelGeneVar(sce   )
#design - like var.regress to regress out certain effects. could regress mt gene variance. Specify the asssay type
dec
```

> Answer:
> 

- Visualise the relation between the mean expression of each gene and the total / biological / technical variance of each gene.

How do you interpret those different values?

```{r}
ggplot(as_tibble(dec)) +
    geom_point(aes(mean, total), color = "black") +
    geom_point(aes(mean, bio), color = "blue") +
    geom_point(aes(mean, tech), color = "red")
#because there is only one tech repeat there the red would be mean of total
#how much more variation occurs than the red trend
#blue is the black minus the trend 
# if a gene has a negative variance it is likely to be negative 
# this graph is showing an assumption. dots that are the furthest from the red line are highly variable, those that are close are likely to be from technical variation. 

#overall... the graph is looking for what is actual variation and what is likely to be technical variation. What is likely to be biologically interesting but not noise. Find the average varation, remove that from the black dots to give the blue dots which are the likely biologically relevant variation. 
```

> Answer:
> 

- Use `scran::getTopHVGs()` to identify highly variable genes (e.g., top 10%).

What is the output?
How many genes do you identify?
Where are those genes located in the mean vs. (biological) variance plot?
What happens to this plot if you set more stringent thresholds to define highly variable genes?

```{r}
hvg <- scran::getTopHVGs(dec,
                         prop = 0.1)
length(hvg)
```


```{r}
## ggplot2
dec$hvg <- rownames(dec) %in% hvg
#if in the vector you with get TRUE, else itll be FALSE
head(dec)
ggplot(as.tibble(dec)) +
 geom_point(aes(x = mean, y = bio, colour = hvg)) 


# y = biological variance 



```

> Answer:
> 
> 

# Exercise

## Dimensionality reduction

- Apply PCA; use `scater` or `BiocSingular`.
  Set a seed to control reproducibility.
  List the names of dimensionality reduction results available.

**Note:** only give the set of highly variable genes to the `scater::runPCA()` function, to save time, memory, and to focus on biologically informative genes in the data set.

```{r}
set.seed(1234)
sce <- scater::runPCA(sce)
?scater::runPCA

percent.var <- attr(reducedDim(sce), "percentVar")

plot(percent.var, xlab="PC", ylab="Variance explained (%)")

reducedDimNames(sce)

```

- Apply UMAP and t-SNE successively on the output of the PCA.
  List the names of dimensionality reduction results available each time.

```{r}
sce <- scater::runUMAP(sce, dimred = "PCA", n_dimred = 7   )

```

```{r}
sce <- scater::runTSNE(sce   )
colData(sce)
rowData(sce)
```

- Visualise the scatterplot of cells produced by each of those dimensionality reduction methods.
  Considering coloring points with quality control metrics.
  
```{r}
sce_umap <- as.data.frame(reducedDim(sce, type = "UMAP"))
head(sce_umap)
sce_umap_plot <- ggplot(sce_umap) +
  geom_point(aes(V1, V2))

sce_tsne <- as.data.frame(reducedDim(sce, type = "TSNE"))
sce_tsne_plot <- ggplot(sce_tsne) +
  geom_point(aes(V1, V2))



cowplot::plot_grid(sce_umap_plot,sce_tsne_plot)
```
  
## Bonus point

- Use `scran::denoisePCA()` to remove principal components that correspond to technical noise, and compare downstream t-SNE or UMAP with those obtained before de-noising.
  Name the output `sce_denoise`.
  How many components remain after denoising?
  Visualise a UMAP of the denoised PCA and compare.

```{r}
sce_denoise <- scran::denoisePCA(   )

```

> Answer:
> 

```{r}
sce_denoise <- scater::runUMAP(   )

```

```{r}
sce_denoise_umap <- 






plot_grid(
    sce_umap + theme(legend.position = "bottom"),
    sce_denoise_umap + theme(legend.position = "bottom"),
    nrow = 1)
```

# Exercise

## Clustering

Cluster cells using `scran`.

- Start with `scran::getClusteredPCs()` to cluster cells after using varying number of PCs, and pick the number of PCs using a heuristic based on the number of clusters.

```{r}
output <- scran::getClusteredPCs(reducedDim(sce, "PCA"))
metadata(output)$chosen

#this gives you the advised number of pcs for your data. 
```

- Use `scran::buildSNNGraph()` and `igraph::cluster_louvain()` with that "ideal" number of PCs.
  Assign the cluster label to a cell metadata column named `"label"`.

```{r, message=FALSE}
pca_sce_data <-  reducedDim(sce, "PCA")[,1:25]# i dont htink this part was useful. You can go back to the PCA function above and change the number of dims to the recommended number
g <-    scran::buildSNNGraph(sce, use.dimred = "PCA") # uses specified numbers of dims used in the PCA function previously used. 


colData(sce)[["label"]] <- factor(igraph::cluster_louvain(g, resolution = 0.5)$membership)
#you can specify the resolution. yesterday we used 0.5 
```

- Visualise the assigned cluster on your preferred dimensionality reduction layout.

**Note:** Dimensionality reduction and clustering are two separate methods both based on the PCA coordinates.
  They may not always agree with each other, often helping to diagnose over- or under-clustering, as well as parameterisation of dimensionality reduction methods.

```{r}
gg_snn <- reducedDim(x = sce, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    bind_cols(colData(sce) %>% as_tibble()) %>%
    sample_frac() %>%
    ggplot() +
    geom_point(aes(V1, V2, color=label)) +
    cowplot::theme_cowplot()
gg_snn
```

## Bonus point

- Test different numbers of principal components and compare results.

```{r, message=FALSE}
snn_plots <- list()
for (d in c(5, 10, 13, 15)) {
    g <- scran::buildSNNGraph(t(reducedDim(sce, "PCA")), d = d)
    colData(sce)[[sprintf("snn_d", d)]] <- factor(igraph::cluster_louvain(g)$membership)
    gg_d <- reducedDim(x = sce, type = "UMAP") %>%
        as.data.frame() %>%
        as_tibble() %>%
        bind_cols(colData(sce) %>% as_tibble()) %>%
        sample_frac() %>%
        ggplot() +
        geom_point(aes(V1, V2, color=snn_d)) +
        labs(title = d) +
        cowplot::theme_cowplot()
    snn_plots[[as.character(d)]] <- gg_d
}
plot_grid(plotlist = snn_plots, ncol = 2)
```

- Try `scran::quickCluster()`; identify key parameters and compare results.

```{r}
sce$quickCluster <- scran::quickCluster(   )

gg_cluster <- reducedDim(x = sce, type = "UMAP") %>%
    as.data.frame() %>%
    as_tibble() %>%
    bind_cols(colData(sce) %>% as_tibble()) %>%
    sample_frac() %>%
    ggplot() +
    geom_point(aes(V1, V2, color=quickCluster)) +
    cowplot::theme_cowplot()
gg_cluster
```

# Exercise

## Cluster markers

- Use `scran::findMarkers()` to identify markers for each cluster.
  Display the metadata of markers for the first cluster.

```{r}
markers <- scran::findMarkers(sce, 
                              groups = sce$label,
                              test.type = "t" # gives logFC but non parametric tests (like wilcox) will not have a logFC
                              )
markers

markers[[1]] #data for the first marker?
```

- Visualise the expression of selected markers:

  + As a dot plot, optionally with a violin layer.

```{r}
marker_id <-    
marker_name <-    








```

  + On a dimensionality reduction layout.
    Compare with the cluster labels.

```{r}
gg_marker <-  








plot_grid(gg_marker, gg_snn)
```

# Exercise

## Interactive visualisation

- Use `iSEE::iSEE()` to launch an interactive web-application to visualise the contents of the `SingleCellExperiment` object.

```{r}
library(iSEE)
app <- iSEE(sce)
if (interactive()) {
  shiny::runApp(app)
}
```

## Bonus point

- Preconfigure the application to start with a subset of panels, e.g.

```{r}
initial_panel_list <- list(
  ReducedDimensionPlot(PanelWidth=4L),
  RowDataTable(PanelWidth=8L)
)
app <- iSEE::iSEE(sce, initial = initial_panel_list)
if (interactive()) {
  shiny::runApp(app)
}
```
